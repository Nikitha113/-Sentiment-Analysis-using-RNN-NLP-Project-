{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBzQR6/bdw/tqNSKVG579H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitha113/-Sentiment-Analysis-using-RNN-NLP-Project-/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jYmSti81Cnk"
      },
      "outputs": [],
      "source": [
        "#Rnn recurrent neural network it deals with shortterm data and LSTM deals with long term data both deals with numerical and also alphabetical data\n",
        "#it deals with time\n",
        "#now lets deal with alphabetical data using RNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#it deals with next word in the given sequence example is after training if we give i love it should predict you after i love"
      ],
      "metadata": {
        "id": "wtVWaVPJ56dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after training something the algorithm should predict the next word"
      ],
      "metadata": {
        "id": "gKANTYTB6IOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "#with the help of sequential we are creating deeplearining brain like inputlayer hiddenlayer and output layer\n",
        "#What is Sequential?\n",
        "#It is a model type in Keras.\n",
        "#Used when layers are stacked one after another (simple flow).\n",
        "#Input â†’ Layer â†’ Layer â†’ Output"
      ],
      "metadata": {
        "id": "d5a8ypQa61yV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "#What is Tokenizer?\n",
        "#Converts text (words) into numbers.\n",
        "#Neural networks cannot understand text, only numbers.\n",
        "#we are dealing with alphabetical data so we need one parameter called Tokenizer\n",
        "#\"I love AI\" I means 1 , love means 2 , AI means 3 its called mapping\n",
        "#the output will be [1, 2, 3]\n",
        "#preprocessing means dealing or formatting or changes with origimal data set"
      ],
      "metadata": {
        "id": "5coq_vnH9J2f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "#Converts labels into one-hot encoded format\n"
      ],
      "metadata": {
        "id": "bdygqYblA3ME"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding,Dense,SimpleRNN\n",
        "#Embedding means meaning of words\n",
        "#What does Embedding do?\n",
        "#Converts word numbers into dense vectors\n",
        "#Captures meaning of words\n",
        "#Example:\n",
        "#Embedding(input_dim=1000, output_dim=64)\n",
        "#This means:\n",
        "#1000 unique words\n",
        "#Each word â†’ 64-dimensional vector\n",
        "#Why important?\n",
        "#Words with similar meaning get similar vectorsmeans"
      ],
      "metadata": {
        "id": "qLlWapUFDUnk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dense\n",
        "#What is Dense?\n",
        "#Fully connected layer\n",
        "#Produces the final output"
      ],
      "metadata": {
        "id": "fZ_8yBBUGfWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SimpleRNN means sequence memory"
      ],
      "metadata": {
        "id": "BmWp9UayHDO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cKZqahqELDyC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sample text data\n",
        "texts = [\n",
        "    \"I love this product\",\n",
        "    \"This is amazing\",\n",
        "    \"I hate this\",\n",
        "    \"Very bad experience\"\n",
        "]"
      ],
      "metadata": {
        "id": "seSQky3lQZ8Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels: 1 = Positive, 0 = Negative\n",
        "labels = [1, 1, 0, 0]\n",
        "#Sentence\tMeaning\tLabel\n",
        "#\"I love this product\"\tPositive\t1\n",
        "#\"This is amazing\"\tPositive\t1\n",
        "#\"I hate this\"\tNegative\t0\n",
        "#\"Very bad experience\"\tNegative\t0\n",
        "#First two sentences â†’ positive\n",
        "#Last two sentences â†’ negative"
      ],
      "metadata": {
        "id": "f4y4i6-IQlJv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Convert text to numbers\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences so all have same length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=5)\n",
        "#Tokenizer converts words into numbers, and padding ensures all sequences have the same length so the neural network can process them."
      ],
      "metadata": {
        "id": "k9MdcFGUQ9rY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. One-hot encode labels\n",
        "labels = to_categorical(labels, num_classes=2)"
      ],
      "metadata": {
        "id": "G8d6b-BzSi2h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Build RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(\n",
        "    input_dim=1000,     # vocabulary size\n",
        "    output_dim=64,      # vector size for each word\n",
        "    input_length=5\n",
        "))\n",
        "# Simple RNN layer\n",
        "model.add(SimpleRNN(32))\n",
        "#Reads the sentence word by word and remembers context.\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(2, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUFfFxvcS4cf",
        "outputId": "bdbfbf50-1d69-417e-a404-912d51712823"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = Sequential()\n",
        "What this means:\n",
        "You are creating an empty neural network.\n",
        "Think of it like an empty pipeline\n",
        "Youâ€™ll now add layers one by one.\n",
        "input_dim = 1000\n",
        "Maximum number of unique words\n",
        "Vocabulary size\n",
        "Meaning:\n",
        "â€œI can handle up to 1000 different words.â€\n",
        "output_dim = 64\n",
        "Size of vector for each word\n",
        "Meaning:\n",
        "â€œEach word will be represented using 64 numbers.â€\n",
        "input_length = 5\n",
        "Length of each sentence after padding"
      ],
      "metadata": {
        "id": "Us_mKF2UWACy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Xfe83d1bU0EA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is an optimizer?\n",
        "Optimizer decides:\n",
        "â€œHow should the model change its weights to reduce mistakes?â€\n",
        "Why Adam?\n",
        "Very popular\n",
        "Fast\n",
        "Works well for most problems\n",
        "Beginner-friendly\n",
        "Think of Adam as:\n",
        "A smart teacher that adjusts learning speed automatically"
      ],
      "metadata": {
        "id": "acKlle__VV9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss = 'categorical_crossentropy'\n",
        "What is loss?\n",
        "Loss tells:\n",
        "â€œHow wrong was the modelâ€™s prediction?â€\n",
        "Lower loss = better model."
      ],
      "metadata": {
        "id": "U0dLzt7KVm7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics = ['accuracy']\n",
        "What is accuracy?\n",
        "Accuracy tells:\n",
        "â€œHow many predictions were correct?â€"
      ],
      "metadata": {
        "id": "FS9042HsWqlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Train the model\n",
        "model.fit(\n",
        "    padded_sequences,\n",
        "    labels,\n",
        "    epochs=20,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U__ma8E6W9Ul",
        "outputId": "9129b635-7b04-45d6-e59d-ba094f006eda"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6786\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.7500 - loss: 0.6449\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.6122\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 0.5805\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.5495\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.5192\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.4895\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.4604\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.4317\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.4036\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.3761\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.3493\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.3231\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2978\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2734\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2499\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2276\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.2063\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1863\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780735b971d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4188729f"
      },
      "source": [
        "# Task\n",
        "Build and train a SimpleRNN model to classify the sentiment of text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4c9c636"
      },
      "source": [
        "## fix_syntax_in_compile_cell\n",
        "\n",
        "### Subtask:\n",
        "Correct the syntax in the model compilation cell to ensure the model is properly initialized for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "926453be"
      },
      "source": [
        "**Reasoning**:\n",
        "The kernel state currently does not contain the 'model' object, and the previous error indicates that the model must be compiled before training. I will redefine the model and then compile it correctly to ensure the training step can proceed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3689fc48",
        "outputId": "40ed3d66-4e4f-4f93-8e42-db29d706e385"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "# Re-building the model to ensure it exists in the current session\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=64))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compiling the model as requested\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model defined and compiled successfully.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model defined and compiled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Test prediction\n",
        "test_text = [\"I love it\"]\n",
        "test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "test_pad = pad_sequences(test_seq, maxlen=5)\n",
        "\n",
        "prediction = model.predict(test_pad)\n",
        "\n",
        "print(\"Prediction:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEhVSJQfZ0jm",
        "outputId": "c4985e0e-919b-4c0c-b5b0-6065bf7111db"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "Prediction: [[0.51174486 0.48825517]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = prediction.argmax(axis=1)\n",
        "print(\"Predicted class:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p2kQX4qaDvZ",
        "outputId": "8b741f59-d2ba-462e-a69e-26c55fbb062f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"I love this product\",\n",
        "    \"I love it\",\n",
        "    \"This is amazing\",\n",
        "    \"I really love this\",\n",
        "    \"Very good experience\",\n",
        "    \"I hate this\",\n",
        "    \"This is bad\",\n",
        "    \"Very bad experience\",\n",
        "    \"I dislike it\"\n",
        "]\n",
        "\n",
        "labels = [1,1,1,1,1,0,0,0,0]\n"
      ],
      "metadata": {
        "id": "o-xxNLxnaFot"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "1gd3__4yaits"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss='binary_crossentropy'\n"
      ],
      "metadata": {
        "id": "FoP-oP-3akvo"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n"
      ],
      "metadata": {
        "id": "ms0QJZe7an35"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(test_pad)\n",
        "\n",
        "# Get predicted class\n",
        "predicted_class = prediction.argmax(axis=1)\n",
        "\n",
        "# Get confidence score\n",
        "confidence = prediction[0][predicted_class[0]]\n",
        "\n",
        "# Print clean result\n",
        "if predicted_class[0] == 1:\n",
        "    print(f\"Sentiment: Positive ğŸ˜Š (Confidence: {confidence:.2f})\")\n",
        "else:\n",
        "    print(f\"Sentiment: Negative ğŸ˜ (Confidence: {confidence:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uTwELKabA3J",
        "outputId": "c415ab0f-4eee-4ca4-a000-be11eef16637"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Sentiment: Negative ğŸ˜ (Confidence: 0.51)\n"
          ]
        }
      ]
    }
  ]
}